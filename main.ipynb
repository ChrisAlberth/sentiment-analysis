{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "COL_NAMES = ['text', 'label']\n",
    "\n",
    "train_df = pd.read_csv(\"./data/train_preprocess.tsv\", sep='\\t', names=COL_NAMES, header=None)\n",
    "valid_df = pd.read_csv(\"./data/valid_preprocess.tsv\", sep='\\t', names=COL_NAMES, header=None)\n",
    "test_df = pd.read_csv(\"./data/test_preprocess.tsv\", sep='\\t', names=COL_NAMES, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import spacy\n",
    "from spacy.lang.id import Indonesian\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def preprocess_text(text):\n",
    "\n",
    "    stop_words = set(stopwords.words(\"indonesian\"))\n",
    "    stop_words = stop_words - {'tidak', 'bukan', 'kurang', 'tak'}\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "    # nlp = Indonesian()\n",
    "    # doc = nlp(text)\n",
    "    # filtered_words = [token.text for token in doc if token.pos_ in {'ADJ', 'VERB'}]\n",
    "    # text = ' '.join(filtered_words)\n",
    "\n",
    "    # factory = StemmerFactory()\n",
    "    # stemmer = factory.create_stemmer()\n",
    "    # text = stemmer.stem(text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "x_train = train_df['text'].apply(preprocess_text)\n",
    "x_valid = valid_df['text'].apply(preprocess_text)\n",
    "x_test = test_df['text'].apply(preprocess_text)\n",
    "\n",
    "y_train = train_df['label']\n",
    "y_valid = valid_df['label']\n",
    "y_test = test_df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(lowercase=True, ngram_range=(1,2), tokenizer=token.tokenize)\n",
    "x_train_cv = cv.fit_transform(x_train)\n",
    "x_valid_cv = cv.transform(x_valid)\n",
    "x_test_cv = cv.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(lowercase=True, ngram_range=(1,2), tokenizer=token.tokenize)\n",
    "x_train_tf = tf.fit_transform(x_train)\n",
    "x_valid_tf = tf.transform(x_valid)\n",
    "x_test_tf = tf.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes + Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi validasi: 0.8476190476190476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.80      0.80       394\n",
      "     neutral       0.95      0.48      0.64       131\n",
      "    positive       0.87      0.94      0.90       735\n",
      "\n",
      "    accuracy                           0.85      1260\n",
      "   macro avg       0.87      0.74      0.78      1260\n",
      "weighted avg       0.85      0.85      0.84      1260\n",
      "\n",
      "Akurasi testing: 0.696\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.93      0.78       204\n",
      "     neutral       0.83      0.11      0.20        88\n",
      "    positive       0.73      0.72      0.72       208\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.74      0.59      0.57       500\n",
      "weighted avg       0.72      0.70      0.65       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_cv = MultinomialNB().fit(x_train_cv, y_train)\n",
    "predicted = nb_cv.predict(x_valid_cv)\n",
    "print(\"Akurasi validasi: \" + str(accuracy_score(y_valid, predicted)))\n",
    "print(classification_report(y_valid, predicted))\n",
    "\n",
    "predicted = nb_cv.predict(x_test_cv)\n",
    "print(\"Akurasi testing: \" + str(accuracy_score(y_test, predicted)))\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression + Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi validasi: 0.8857142857142857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.88      0.85       394\n",
      "     neutral       0.87      0.66      0.75       131\n",
      "    positive       0.92      0.93      0.92       735\n",
      "\n",
      "    accuracy                           0.89      1260\n",
      "   macro avg       0.87      0.82      0.84      1260\n",
      "weighted avg       0.89      0.89      0.88      1260\n",
      "\n",
      "Akurasi testing: 0.802\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.92      0.84       204\n",
      "     neutral       0.69      0.42      0.52        88\n",
      "    positive       0.86      0.85      0.86       208\n",
      "\n",
      "    accuracy                           0.80       500\n",
      "   macro avg       0.77      0.73      0.74       500\n",
      "weighted avg       0.80      0.80      0.79       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_cv = LogisticRegression().fit(x_train_cv, y_train)\n",
    "predicted = lr_cv.predict(x_valid_cv)\n",
    "print(\"Akurasi validasi: \" + str(accuracy_score(y_valid, predicted)))\n",
    "print(classification_report(y_valid, predicted))\n",
    "\n",
    "predicted = lr_cv.predict(x_test_cv)\n",
    "print(\"Akurasi testing: \" + str(accuracy_score(y_test, predicted)))\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest + Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi validasi: 0.8571428571428571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.80      0.81       394\n",
      "     neutral       0.88      0.44      0.59       131\n",
      "    positive       0.87      0.96      0.91       735\n",
      "\n",
      "    accuracy                           0.86      1260\n",
      "   macro avg       0.86      0.74      0.77      1260\n",
      "weighted avg       0.86      0.86      0.85      1260\n",
      "\n",
      "Akurasi testing: 0.714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.90      0.76       204\n",
      "     neutral       0.82      0.20      0.33        88\n",
      "    positive       0.79      0.75      0.77       208\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.75      0.62      0.62       500\n",
      "weighted avg       0.74      0.71      0.69       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest_cv = RandomForestClassifier(n_estimators=100).fit(x_train_cv, y_train)\n",
    "predicted = forest_cv.predict(x_valid_cv)\n",
    "print(\"Akurasi validasi: \" + str(accuracy_score(y_valid, predicted)))\n",
    "print(classification_report(y_valid, predicted))\n",
    "\n",
    "predicted = forest_cv.predict(x_test_cv)\n",
    "print(\"Akurasi testing: \" + str(accuracy_score(y_test, predicted)))\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes + TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi validasi: 0.7825396825396825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.63      0.71       394\n",
      "     neutral       1.00      0.14      0.24       131\n",
      "    positive       0.77      0.98      0.86       735\n",
      "\n",
      "    accuracy                           0.78      1260\n",
      "   macro avg       0.86      0.58      0.60      1260\n",
      "weighted avg       0.81      0.78      0.75      1260\n",
      "\n",
      "Akurasi testing: 0.652\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.66      0.72       204\n",
      "     neutral       1.00      0.02      0.04        88\n",
      "    positive       0.57      0.91      0.70       208\n",
      "\n",
      "    accuracy                           0.65       500\n",
      "   macro avg       0.79      0.53      0.49       500\n",
      "weighted avg       0.74      0.65      0.60       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_tf = MultinomialNB().fit(x_train_tf, y_train)\n",
    "predicted = nb_tf.predict(x_valid_tf)\n",
    "print(\"Akurasi validasi: \" + str(accuracy_score(y_valid, predicted)))\n",
    "print(classification_report(y_valid, predicted))\n",
    "\n",
    "predicted = nb_tf.predict(x_test_cv)\n",
    "print(\"Akurasi testing: \" + str(accuracy_score(y_test, predicted)))\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression + TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi validasi: 0.8753968253968254\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.86      0.83       394\n",
      "     neutral       0.91      0.51      0.65       131\n",
      "    positive       0.91      0.95      0.93       735\n",
      "\n",
      "    accuracy                           0.88      1260\n",
      "   macro avg       0.87      0.77      0.80      1260\n",
      "weighted avg       0.88      0.88      0.87      1260\n",
      "\n",
      "Akurasi testing: 0.762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.94      0.81       204\n",
      "     neutral       0.85      0.26      0.40        88\n",
      "    positive       0.82      0.80      0.81       208\n",
      "\n",
      "    accuracy                           0.76       500\n",
      "   macro avg       0.79      0.67      0.67       500\n",
      "weighted avg       0.78      0.76      0.74       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_tf = LogisticRegression().fit(x_train_tf, y_train)\n",
    "predicted = lr_tf.predict(x_valid_tf)\n",
    "print(\"Akurasi validasi: \" + str(accuracy_score(y_valid, predicted)))\n",
    "print(classification_report(y_valid, predicted))\n",
    "\n",
    "predicted = lr_tf.predict(x_test_tf)\n",
    "print(\"Akurasi testing: \" + str(accuracy_score(y_test, predicted)))\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest + TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi validasi: 0.8626984126984127\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.82      0.82       394\n",
      "     neutral       0.87      0.47      0.61       131\n",
      "    positive       0.89      0.95      0.92       735\n",
      "\n",
      "    accuracy                           0.86      1260\n",
      "   macro avg       0.86      0.75      0.78      1260\n",
      "weighted avg       0.86      0.86      0.86      1260\n",
      "\n",
      "Akurasi testing: 0.682\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.89      0.73       204\n",
      "     neutral       0.86      0.22      0.35        88\n",
      "    positive       0.76      0.67      0.71       208\n",
      "\n",
      "    accuracy                           0.68       500\n",
      "   macro avg       0.75      0.59      0.60       500\n",
      "weighted avg       0.72      0.68      0.66       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest_tf = RandomForestClassifier(n_estimators=100).fit(x_train_tf, y_train)\n",
    "predicted = forest_tf.predict(x_valid_tf)\n",
    "print(\"Akurasi validasi: \" + str(accuracy_score(y_valid, predicted)))\n",
    "print(classification_report(y_valid, predicted))\n",
    "\n",
    "predicted = forest_tf.predict(x_test_tf)\n",
    "print(\"Akurasi testing: \" + str(accuracy_score(y_test, predicted)))\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
